{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soccer1356-2000/Ingong_MidtermExam/blob/main/%EC%A4%91%EA%B0%84%EA%B3%BC%EC%A0%9C_201920778_%EC%9D%B4%EC%8A%B9%EC%9C%A4_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']= 500\n",
        "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
        "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
        "args['momentum']=0.9 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "args['weight_decay']=1e-5\n",
        "\n",
        "args['seed']=1 #random seed\n",
        "args['log_interval']=5000 // args['batch_size']\n",
        "args['cuda']=True\n"
      ],
      "metadata": {
        "id": "QrIE9UAm0d0b"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FoWYQ5rfLSLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6dec07-849e-4f17-a845-621e2430ca01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 19258107.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 337649.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6406622.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5582284.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms # Fashion-MNIST dataset for PyTorch\n",
        "# Download and load the FashionMNIST training data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True,\n",
        "transform = transform)\n",
        "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False,\n",
        "transform = transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args['batch_size'], shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=args['batch_size'], shuffle=True)"
      ],
      "metadata": {
        "id": "FbEBR-PBNQbC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset # 28 * 28 * 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZcKmEcXa6BP",
        "outputId": "4c06fb4b-f1ec-4589-ae26-656c086f0577"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: MNIST_data/\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5,), std=(0.5,))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6yjaet1MoX-Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, groups=groups, bias=False)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
      ],
      "metadata": {
        "id": "-lSZGD5wndIa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64,  norm_layer=nn.BatchNorm2d):\n",
        "      \n",
        "        super().__init__()\n",
        "            \n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)  \n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "            \n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "BKX_QBynryp8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, norm_layer=nn.BatchNorm2d):\n",
        "        super().__init__()\n",
        "\n",
        "        # ResNext\n",
        "       # width = int(planes * (base_width / 64.)) * groups\n",
        "        width = planes\n",
        "        \n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups) # conv2에서 downsample\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        # 1x1 convolution layer\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        # 3x3 convolution layer\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        # 1x1 convolution layer\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "CimQEbX0sfJN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, layers, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, norm_layer=nn.BatchNorm2d):\n",
        "    super().__init__()\n",
        "    self.norm_layer = norm_layer\n",
        "    self.groups = groups\n",
        "    self.base_width = width_per_group\n",
        "\n",
        "    self.inplane = 64\n",
        "\n",
        "    #stage 1\n",
        "    self.conv1 = nn.Conv2d(1,self.inplane,kernel_size=7,stride = 2, padding = 3, bias = False)\n",
        "    self.bn1 = norm_layer(self.inplane)\n",
        "    self.relu = nn.ReLU(inplace = True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    #stage 2\n",
        "    self.layer1 = self.make_layer(block,64,layers[0])\n",
        "    #stage 3\n",
        "    self.layer2 = self.make_layer(block,128,layers[1],stride=2)\n",
        "    #stage 4\n",
        "    self.layer3 = self.make_layer(block,256,layers[2],stride=2)\n",
        "    #stage 5\n",
        "    self.layer4 = self.make_layer(block,512,layers[3],stride=2)\n",
        "    self.averpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512 * block.expansion,10)\n",
        "  \n",
        "  def make_layer(self,block,palnes,blocks,stride = 1):\n",
        "    norm_layer = self.norm_layer\n",
        "\n",
        "    down_channel = None\n",
        "    \n",
        "    if stride != 1 or self.inplane != block.expansion * palnes:\n",
        "      down_channel = nn.Sequential(conv1x1(self.inplane, palnes * block.expansion,stride),norm_layer(palnes * block.expansion))\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    layers.append(block(self.inplane, palnes, stride, down_channel, self.groups,self.base_width, norm_layer))\n",
        "    self.inplane = palnes * block.expansion # inplanes 업데이트\n",
        "    for _ in range(1, blocks):\n",
        "        layers.append(block(self.inplane, palnes, groups=self.groups,base_width=self.base_width, norm_layer=norm_layer))\n",
        "       # self.inplane = palnes * block.expansion # inplanes 업데이트\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "\n",
        "    x = self.averpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "   # output = nn.log_softmax(x, dim=1)\n",
        "    return F.log_softmax(x)"
      ],
      "metadata": {
        "id": "yjZKnwgct0hB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "G_UN2T5709Rs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        #Variables in Pytorch are differenciable. \n",
        "        data, target = Variable(data), Variable(target)\n",
        "        #This will zero out the gradients for this batch. \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        train_pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        train_correct += train_pred.eq(target.data.view_as(train_pred)).long().cpu().sum()\n",
        "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "        loss = F.nll_loss(output, target)\n",
        "        #dloss/dx for every Variable \n",
        "        loss.backward()\n",
        "        #to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        #Print out the loss periodically. \n",
        "        if batch_idx % args['log_interval'] == 0:\n",
        "            train_correct = 0\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
        "                100. * batch_idx / len(trainloader), loss.data))\n",
        "    train_acc.insert(len(train_acc),(100. * train_correct / len(trainloader.dataset)))\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    correct_top5 = 0\n",
        "    total = 0\n",
        "    total_r=0\n",
        "    correct_top1=0\n",
        "    for data, target in testloader:\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "        _, predicted = torch.topk(output, k=5, dim=1)\n",
        "        total += target.size(0)\n",
        "        correct_top5 += sum([1 if label in predicted[i] else 0  for i,label in enumerate(target)])\n",
        "\n",
        "        __, predicted_r = torch.max(output, 1)\n",
        "        total_r += target.size(0)\n",
        "        correct_top1 += (predicted_r == target).sum().item()\n",
        "\n",
        "    test_loss /= len(testloader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        test_loss, correct, len(testloader.dataset),\n",
        "        100. * correct / len(testloader.dataset)))\n",
        "    test_acc.insert(len(test_acc),(100. * correct / len(testloader.dataset)))\n",
        "    top5_accuracy = correct_top5 / total\n",
        "    print(f\"Top-5 Accuracy: {top5_accuracy}\")\n",
        "    top1_accuracy = correct_top1 / total_r\n",
        "    print(f\"Top-1 Accuracy: {top1_accuracy}\\n\")\n",
        "  "
      ],
      "metadata": {
        "id": "URFhhVfUutlU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9iyKkvXDkUc",
        "outputId": "48172f10-f591-4874-eff4-689a2fbfbea8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->ptflops) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->ptflops) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.7-py3-none-any.whl size=11076 sha256=042ea865d62f4c220dc5b6cd0a3d2f43c9452bb501bfe720270f21580c5b2137\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/54/3b/f84523431ce82e08462644d279c0e13a51a00236e237e6bc7e\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from ptflops import get_model_complexity_info\n",
        "import math\n",
        "import time"
      ],
      "metadata": {
        "id": "6m_HDnysAp5c"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "model = ResNet(Bottleneck,[3,4,6,3])\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'],weight_decay=args['weight_decay'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "\n",
        "  input_tensor = torch.randn(1, 1, 224, 224).cuda()\n",
        "\n",
        "  flops, params = get_model_complexity_info(model, (1, 224, 224), as_strings=True, print_per_layer_stat=True)\n",
        "\n",
        "  print('FLOPs:', flops)\n",
        "\n",
        "  print('Parameters:', params)\n",
        "\n",
        "\n",
        "print(test_acc)\n",
        "print(train_acc)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot([i for i in range(1,len(test_acc)+1)], test_acc, color =\"blue\")\n",
        "a = plt.twinx()\n",
        "a.plot([i for i in range(1,len(train_acc)+1)], train_acc, color = \"red\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j6MJRqJ20YDM",
        "outputId": "ebf8bd21-e1fd-4e96-d396-cab2df59301b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-a8a4df10e8b6>:60: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.760639\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.437494\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.677332\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.568401\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.619797\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.562264\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.523324\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.554072\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.471144\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.427103\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.425129\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.434698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-d3b87ec97dcd>:38: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data, target = Variable(data, volatile=True), Variable(target)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4658, Accuracy: 8194/10000 (82%)\n",
            "Top-5 Accuracy: 0.9973\n",
            "Top-1 Accuracy: 0.8194\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.443623\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.421231\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.438670\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.415875\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.396305\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.389032\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.371714\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.320574\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.358266\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.388775\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.375399\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.363759\n",
            "\n",
            "Test set: Average loss: 0.3821, Accuracy: 8590/10000 (86%)\n",
            "Top-5 Accuracy: 0.9973\n",
            "Top-1 Accuracy: 0.859\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.273428\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.322349\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.344557\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.322168\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.341519\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.341190\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.296714\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.314811\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.260053\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.319194\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.397702\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.347606\n",
            "\n",
            "Test set: Average loss: 0.3753, Accuracy: 8635/10000 (86%)\n",
            "Top-5 Accuracy: 0.9974\n",
            "Top-1 Accuracy: 0.8635\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.285437\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.251310\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.281595\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.325307\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.235402\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.231756\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.218203\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.243892\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.278279\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.273682\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.280630\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.272331\n",
            "\n",
            "Test set: Average loss: 0.3420, Accuracy: 8728/10000 (87%)\n",
            "Top-5 Accuracy: 0.9972\n",
            "Top-1 Accuracy: 0.8728\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.265363\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.239545\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.291274\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.239439\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.265914\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.262476\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.242101\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.230625\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.220831\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.240928\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.289170\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.241920\n",
            "\n",
            "Test set: Average loss: 0.3295, Accuracy: 8790/10000 (88%)\n",
            "Top-5 Accuracy: 0.9981\n",
            "Top-1 Accuracy: 0.879\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.206738\n",
            "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.198108\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.213864\n",
            "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.250370\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.226740\n",
            "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.269688\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.259616\n",
            "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.202898\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.212269\n",
            "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.261496\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.203851\n",
            "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.191734\n",
            "\n",
            "Test set: Average loss: 0.3403, Accuracy: 8811/10000 (88%)\n",
            "Top-5 Accuracy: 0.9978\n",
            "Top-1 Accuracy: 0.8811\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.172330\n",
            "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.196635\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.209999\n",
            "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.206737\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.216135\n",
            "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.200848\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.215360\n",
            "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.248685\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.255029\n",
            "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.248926\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.170998\n",
            "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.207378\n",
            "\n",
            "Test set: Average loss: 0.3364, Accuracy: 8826/10000 (88%)\n",
            "Top-5 Accuracy: 0.9988\n",
            "Top-1 Accuracy: 0.8826\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.178962\n",
            "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.220075\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.183833\n",
            "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.179977\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.166923\n",
            "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.163726\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.192768\n",
            "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.219413\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.186523\n",
            "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.182193\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.175337\n",
            "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.175647\n",
            "\n",
            "Test set: Average loss: 0.3551, Accuracy: 8794/10000 (88%)\n",
            "Top-5 Accuracy: 0.9988\n",
            "Top-1 Accuracy: 0.8794\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.152876\n",
            "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.128318\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.163755\n",
            "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.240079\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.131101\n",
            "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.180678\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.162269\n",
            "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.167003\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.177524\n",
            "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.157869\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.198107\n",
            "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.219098\n",
            "\n",
            "Test set: Average loss: 0.3082, Accuracy: 8965/10000 (90%)\n",
            "Top-5 Accuracy: 0.9988\n",
            "Top-1 Accuracy: 0.8965\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.142527\n",
            "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.131930\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.144628\n",
            "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.148896\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.123561\n",
            "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.168240\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.171080\n",
            "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.153130\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.185682\n",
            "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.164674\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.143007\n",
            "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.188261\n",
            "\n",
            "Test set: Average loss: 0.3297, Accuracy: 8915/10000 (89%)\n",
            "Top-5 Accuracy: 0.9992\n",
            "Top-1 Accuracy: 0.8915\n",
            "\n",
            "300.35032 sec\n",
            "ResNet(\n",
            "  23.52 M, 100.000% Params, 4.04 GMac, 100.000% MACs, \n",
            "  (conv1): Conv2d(3.14 k, 0.013% Params, 39.34 MMac, 0.973% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.040% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.020% MACs, inplace=True)\n",
            "  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.020% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    215.81 k, 0.917% Params, 680.39 MMac, 16.836% MACs, \n",
            "    (0): Bottleneck(\n",
            "      75.01 k, 0.319% Params, 236.43 MMac, 5.850% MACs, \n",
            "      (conv1): Conv2d(4.1 k, 0.017% Params, 12.85 MMac, 0.318% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(36.86 k, 0.157% Params, 115.61 MMac, 2.861% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.040% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.030% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        16.9 k, 0.072% Params, 52.99 MMac, 1.311% MACs, \n",
            "        (0): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.040% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      70.4 k, 0.299% Params, 221.98 MMac, 5.493% MACs, \n",
            "      (conv1): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(36.86 k, 0.157% Params, 115.61 MMac, 2.861% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.040% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.030% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      70.4 k, 0.299% Params, 221.98 MMac, 5.493% MACs, \n",
            "      (conv1): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(36.86 k, 0.157% Params, 115.61 MMac, 2.861% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.040% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.030% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    1.22 M, 5.185% Params, 1.04 GMac, 25.649% MACs, \n",
            "    (0): Bottleneck(\n",
            "      379.39 k, 1.613% Params, 376.02 MMac, 9.305% MACs, \n",
            "      (conv1): Conv2d(32.77 k, 0.139% Params, 102.76 MMac, 2.543% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.020% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(147.46 k, 0.627% Params, 115.61 MMac, 2.861% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        132.1 k, 0.562% Params, 103.56 MMac, 2.563% MACs, \n",
            "        (0): Conv2d(131.07 k, 0.557% Params, 102.76 MMac, 2.543% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      280.06 k, 1.191% Params, 220.17 MMac, 5.448% MACs, \n",
            "      (conv1): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(147.46 k, 0.627% Params, 115.61 MMac, 2.861% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      280.06 k, 1.191% Params, 220.17 MMac, 5.448% MACs, \n",
            "      (conv1): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(147.46 k, 0.627% Params, 115.61 MMac, 2.861% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      280.06 k, 1.191% Params, 220.17 MMac, 5.448% MACs, \n",
            "      (conv1): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(147.46 k, 0.627% Params, 115.61 MMac, 2.861% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    7.1 M, 30.177% Params, 1.47 GMac, 36.390% MACs, \n",
            "    (0): Bottleneck(\n",
            "      1.51 M, 6.430% Params, 374.26 MMac, 9.261% MACs, \n",
            "      (conv1): Conv2d(131.07 k, 0.557% Params, 102.76 MMac, 2.543% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        526.34 k, 2.238% Params, 103.16 MMac, 2.553% MACs, \n",
            "        (0): Conv2d(524.29 k, 2.229% Params, 102.76 MMac, 2.543% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    14.96 M, 63.619% Params, 811.02 MMac, 20.069% MACs, \n",
            "    (0): Bottleneck(\n",
            "      6.04 M, 25.676% Params, 373.38 MMac, 9.239% MACs, \n",
            "      (conv1): Conv2d(524.29 k, 2.229% Params, 102.76 MMac, 2.543% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(2.36 M, 10.030% Params, 115.61 MMac, 2.861% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(4.1 k, 0.017% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.006% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        2.1 M, 8.933% Params, 102.96 MMac, 2.548% MACs, \n",
            "        (0): Conv2d(2.1 M, 8.916% Params, 102.76 MMac, 2.543% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(4.1 k, 0.017% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      4.46 M, 18.972% Params, 218.82 MMac, 5.415% MACs, \n",
            "      (conv1): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(2.36 M, 10.030% Params, 115.61 MMac, 2.861% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(4.1 k, 0.017% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      4.46 M, 18.972% Params, 218.82 MMac, 5.415% MACs, \n",
            "      (conv1): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(2.36 M, 10.030% Params, 115.61 MMac, 2.861% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(4.1 k, 0.017% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (averpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))\n",
            "  (fc): Linear(20.49 k, 0.087% Params, 20.49 KMac, 0.001% MACs, in_features=2048, out_features=10, bias=True)\n",
            ")\n",
            "FLOPs: 4.04 GMac\n",
            "Parameters: 23.52 M\n",
            "[tensor(81.9400), tensor(85.9000), tensor(86.3500), tensor(87.2800), tensor(87.9000), tensor(88.1100), tensor(88.2600), tensor(87.9400), tensor(89.6500), tensor(89.1500)]\n",
            "[tensor(6.3950), tensor(6.5183), tensor(6.5650), tensor(6.6650), tensor(6.7500), tensor(6.8233), tensor(6.8717), tensor(6.9450), tensor(6.9400), tensor(7.0417)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNeXt\n",
        "torch.cuda.empty_cache()\n",
        "start = time.time()\n",
        "model = ResNet(Bottleneck,[3,4,6,3],groups=32)\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'],weight_decay=args['weight_decay'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "end = time.time()\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "\n",
        "  input_tensor = torch.randn(1, 1, 224, 224).cuda()\n",
        "\n",
        "  flops, params = get_model_complexity_info(model, (1, 224, 224), as_strings=True, print_per_layer_stat=True)\n",
        "\n",
        "  print('FLOPs:', flops)\n",
        "\n",
        "  print('Parameters:', params)\n",
        "\n",
        "\n",
        "print(test_acc)\n",
        "print(train_acc)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot([i for i in range(1,len(test_acc)+1)], test_acc, color =\"blue\")\n",
        "a = plt.twinx()\n",
        "a.plot([i for i in range(1,len(train_acc)+1)], train_acc, color = \"red\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IL_sKr34slks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad11dd93-eb38-443c-c63e-57f95c07a58b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-a8a4df10e8b6>:60: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.680824\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.590088\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.075577\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.852833\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.685056\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.666363\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.607861\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.473888\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.496469\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.574040\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.455333\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.469229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-d3b87ec97dcd>:38: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data, target = Variable(data, volatile=True), Variable(target)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4903, Accuracy: 8301/10000 (83%)\n",
            "Top-5 Accuracy: 0.9961\n",
            "Top-1 Accuracy: 0.8301\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.376078\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.460516\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.347657\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.399911\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.359161\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.502947\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.341092\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.365716\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.367756\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.387692\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.350158\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.400276\n",
            "\n",
            "Test set: Average loss: 0.4131, Accuracy: 8589/10000 (86%)\n",
            "Top-5 Accuracy: 0.997\n",
            "Top-1 Accuracy: 0.8589\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.241565\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.403431\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.307412\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.296436\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.263782\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.272340\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.261898\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.282566\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.316820\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.322361\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.313696\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.336397\n",
            "\n",
            "Test set: Average loss: 0.3712, Accuracy: 8650/10000 (86%)\n",
            "Top-5 Accuracy: 0.9977\n",
            "Top-1 Accuracy: 0.865\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.278213\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.270479\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.209539\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.249240\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.242573\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.314429\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.318767\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.302303\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.292913\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.288057\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.231416\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.250100\n",
            "\n",
            "Test set: Average loss: 0.3747, Accuracy: 8703/10000 (87%)\n",
            "Top-5 Accuracy: 0.9979\n",
            "Top-1 Accuracy: 0.8703\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.192528\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.234824\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.210528\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.257949\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.207021\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.198018\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.274271\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.246242\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.239919\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.243285\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.236999\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.209465\n",
            "\n",
            "Test set: Average loss: 0.3577, Accuracy: 8797/10000 (88%)\n",
            "Top-5 Accuracy: 0.9983\n",
            "Top-1 Accuracy: 0.8797\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.178430\n",
            "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.227890\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.151451\n",
            "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.208101\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.181556\n",
            "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.189111\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.166620\n",
            "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.204054\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.187896\n",
            "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.266698\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.231890\n",
            "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.202578\n",
            "\n",
            "Test set: Average loss: 0.3617, Accuracy: 8803/10000 (88%)\n",
            "Top-5 Accuracy: 0.9976\n",
            "Top-1 Accuracy: 0.8803\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.124019\n",
            "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.195368\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.201852\n",
            "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.192461\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.186697\n",
            "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.207533\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.159954\n",
            "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.201150\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.211152\n",
            "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.178712\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.238072\n",
            "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.188717\n",
            "\n",
            "Test set: Average loss: 0.4042, Accuracy: 8716/10000 (87%)\n",
            "Top-5 Accuracy: 0.9974\n",
            "Top-1 Accuracy: 0.8716\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.160285\n",
            "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.167686\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.115681\n",
            "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.114188\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.162231\n",
            "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.180505\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.163059\n",
            "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.216470\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.152470\n",
            "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.196390\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.221685\n",
            "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.177156\n",
            "\n",
            "Test set: Average loss: 0.3689, Accuracy: 8802/10000 (88%)\n",
            "Top-5 Accuracy: 0.9976\n",
            "Top-1 Accuracy: 0.8802\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.133437\n",
            "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.127029\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.161867\n",
            "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.103839\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.167983\n",
            "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.124648\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.100583\n",
            "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.164568\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.087238\n",
            "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.138574\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.174262\n",
            "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.150027\n",
            "\n",
            "Test set: Average loss: 0.4281, Accuracy: 8745/10000 (87%)\n",
            "Top-5 Accuracy: 0.9981\n",
            "Top-1 Accuracy: 0.8745\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.129713\n",
            "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.128621\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.097809\n",
            "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.154052\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.123261\n",
            "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.168903\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.137733\n",
            "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.158816\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.135510\n",
            "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.128793\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.162612\n",
            "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.116701\n",
            "\n",
            "Test set: Average loss: 0.4221, Accuracy: 8813/10000 (88%)\n",
            "Top-5 Accuracy: 0.9981\n",
            "Top-1 Accuracy: 0.8813\n",
            "\n",
            "262.60531 sec\n",
            "ResNet(\n",
            "  12.56 M, 100.000% Params, 2.25 GMac, 100.000% MACs, \n",
            "  (conv1): Conv2d(3.14 k, 0.025% Params, 39.34 MMac, 1.749% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.071% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.036% MACs, inplace=True)\n",
            "  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.036% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    108.67 k, 0.865% Params, 344.41 MMac, 15.312% MACs, \n",
            "    (0): Bottleneck(\n",
            "      39.3 k, 0.313% Params, 124.44 MMac, 5.532% MACs, \n",
            "      (conv1): Conv2d(4.1 k, 0.033% Params, 12.85 MMac, 0.571% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.018% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1.15 k, 0.009% Params, 3.61 MMac, 0.161% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.018% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(16.38 k, 0.130% Params, 51.38 MMac, 2.284% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, 0.004% Params, 1.61 MMac, 0.071% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.054% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        16.9 k, 0.135% Params, 52.99 MMac, 2.356% MACs, \n",
            "        (0): Conv2d(16.38 k, 0.130% Params, 51.38 MMac, 2.284% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, 0.004% Params, 1.61 MMac, 0.071% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      34.69 k, 0.276% Params, 109.99 MMac, 4.890% MACs, \n",
            "      (conv1): Conv2d(16.38 k, 0.130% Params, 51.38 MMac, 2.284% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.018% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1.15 k, 0.009% Params, 3.61 MMac, 0.161% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.018% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(16.38 k, 0.130% Params, 51.38 MMac, 2.284% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, 0.004% Params, 1.61 MMac, 0.071% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.054% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      34.69 k, 0.276% Params, 109.99 MMac, 4.890% MACs, \n",
            "      (conv1): Conv2d(16.38 k, 0.130% Params, 51.38 MMac, 2.284% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.018% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1.15 k, 0.009% Params, 3.61 MMac, 0.161% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.018% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(16.38 k, 0.130% Params, 51.38 MMac, 2.284% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, 0.004% Params, 1.61 MMac, 0.071% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.054% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    648.19 k, 5.161% Params, 588.56 MMac, 26.166% MACs, \n",
            "    (0): Bottleneck(\n",
            "      236.54 k, 1.884% Params, 264.03 MMac, 11.738% MACs, \n",
            "      (conv1): Conv2d(32.77 k, 0.261% Params, 102.76 MMac, 4.568% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.002% Params, 802.82 KMac, 0.036% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(4.61 k, 0.037% Params, 3.61 MMac, 0.161% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.009% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.522% Params, 51.38 MMac, 2.284% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.008% Params, 802.82 KMac, 0.036% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.040% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        132.1 k, 1.052% Params, 103.56 MMac, 4.604% MACs, \n",
            "        (0): Conv2d(131.07 k, 1.044% Params, 102.76 MMac, 4.568% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1.02 k, 0.008% Params, 802.82 KMac, 0.036% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      137.22 k, 1.093% Params, 108.18 MMac, 4.809% MACs, \n",
            "      (conv1): Conv2d(65.54 k, 0.522% Params, 51.38 MMac, 2.284% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.009% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(4.61 k, 0.037% Params, 3.61 MMac, 0.161% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.009% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.522% Params, 51.38 MMac, 2.284% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.008% Params, 802.82 KMac, 0.036% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.027% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      137.22 k, 1.093% Params, 108.18 MMac, 4.809% MACs, \n",
            "      (conv1): Conv2d(65.54 k, 0.522% Params, 51.38 MMac, 2.284% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.009% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(4.61 k, 0.037% Params, 3.61 MMac, 0.161% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.009% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.522% Params, 51.38 MMac, 2.284% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.008% Params, 802.82 KMac, 0.036% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.027% MACs, inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      137.22 k, 1.093% Params, 108.18 MMac, 4.809% MACs, \n",
            "      (conv1): Conv2d(65.54 k, 0.522% Params, 51.38 MMac, 2.284% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.009% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(4.61 k, 0.037% Params, 3.61 MMac, 0.161% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.002% Params, 200.7 KMac, 0.009% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.522% Params, 51.38 MMac, 2.284% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.008% Params, 802.82 KMac, 0.036% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.027% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    3.67 M, 29.223% Params, 798.65 MMac, 35.506% MACs, \n",
            "    (0): Bottleneck(\n",
            "      941.06 k, 7.493% Params, 262.27 MMac, 11.660% MACs, \n",
            "      (conv1): Conv2d(131.07 k, 1.044% Params, 102.76 MMac, 4.568% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.004% Params, 401.41 KMac, 0.018% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(18.43 k, 0.147% Params, 3.61 MMac, 0.161% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.016% Params, 401.41 KMac, 0.018% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.020% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        526.34 k, 4.191% Params, 103.16 MMac, 4.586% MACs, \n",
            "        (0): Conv2d(524.29 k, 4.175% Params, 102.76 MMac, 4.568% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2.05 k, 0.016% Params, 401.41 KMac, 0.018% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      545.79 k, 4.346% Params, 107.28 MMac, 4.769% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(18.43 k, 0.147% Params, 3.61 MMac, 0.161% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.016% Params, 401.41 KMac, 0.018% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.013% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      545.79 k, 4.346% Params, 107.28 MMac, 4.769% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(18.43 k, 0.147% Params, 3.61 MMac, 0.161% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.016% Params, 401.41 KMac, 0.018% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.013% MACs, inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      545.79 k, 4.346% Params, 107.28 MMac, 4.769% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(18.43 k, 0.147% Params, 3.61 MMac, 0.161% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.016% Params, 401.41 KMac, 0.018% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.013% MACs, inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      545.79 k, 4.346% Params, 107.28 MMac, 4.769% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(18.43 k, 0.147% Params, 3.61 MMac, 0.161% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.016% Params, 401.41 KMac, 0.018% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.013% MACs, inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      545.79 k, 4.346% Params, 107.28 MMac, 4.769% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(18.43 k, 0.147% Params, 3.61 MMac, 0.161% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.004% Params, 100.35 KMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 2.087% Params, 51.38 MMac, 2.284% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.016% Params, 401.41 KMac, 0.018% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.013% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    8.11 M, 64.561% Params, 475.04 MMac, 21.119% MACs, \n",
            "    (0): Bottleneck(\n",
            "      3.75 M, 29.892% Params, 261.39 MMac, 11.621% MACs, \n",
            "      (conv1): Conv2d(524.29 k, 4.175% Params, 102.76 MMac, 4.568% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1.02 k, 0.008% Params, 200.7 KMac, 0.009% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(73.73 k, 0.587% Params, 3.61 MMac, 0.161% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(1.02 k, 0.008% Params, 50.18 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1.05 M, 8.349% Params, 51.38 MMac, 2.284% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(4.1 k, 0.033% Params, 200.7 KMac, 0.009% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.010% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        2.1 M, 16.731% Params, 102.96 MMac, 4.577% MACs, \n",
            "        (0): Conv2d(2.1 M, 16.699% Params, 102.76 MMac, 4.568% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(4.1 k, 0.033% Params, 200.7 KMac, 0.009% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      2.18 M, 17.335% Params, 106.82 MMac, 4.749% MACs, \n",
            "      (conv1): Conv2d(1.05 M, 8.349% Params, 51.38 MMac, 2.284% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1.02 k, 0.008% Params, 50.18 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(73.73 k, 0.587% Params, 3.61 MMac, 0.161% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(1.02 k, 0.008% Params, 50.18 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1.05 M, 8.349% Params, 51.38 MMac, 2.284% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(4.1 k, 0.033% Params, 200.7 KMac, 0.009% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      2.18 M, 17.335% Params, 106.82 MMac, 4.749% MACs, \n",
            "      (conv1): Conv2d(1.05 M, 8.349% Params, 51.38 MMac, 2.284% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1.02 k, 0.008% Params, 50.18 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(73.73 k, 0.587% Params, 3.61 MMac, 0.161% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(1.02 k, 0.008% Params, 50.18 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1.05 M, 8.349% Params, 51.38 MMac, 2.284% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(4.1 k, 0.033% Params, 200.7 KMac, 0.009% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (averpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.004% MACs, output_size=(1, 1))\n",
            "  (fc): Linear(20.49 k, 0.163% Params, 20.49 KMac, 0.001% MACs, in_features=2048, out_features=10, bias=True)\n",
            ")\n",
            "FLOPs: 2.25 GMac\n",
            "Parameters: 12.56 M\n",
            "[tensor(83.0100), tensor(85.8900), tensor(86.5000), tensor(87.0300), tensor(87.9700), tensor(88.0300), tensor(87.1600), tensor(88.0200), tensor(87.4500), tensor(88.1300)]\n",
            "[tensor(6.2000), tensor(6.4667), tensor(6.6533), tensor(6.7367), tensor(6.8450), tensor(6.8850), tensor(6.8817), tensor(6.9700), tensor(6.9983), tensor(7.0683)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}