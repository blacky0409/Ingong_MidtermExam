{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNSva3Mws/lKGLIT0Np/GQA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soccer1356-2000/Ingong_MidtermExam/blob/main/%EC%A4%91%EA%B0%84%EA%B3%BC%EC%A0%9C_201920778_%EC%9D%B4%EC%8A%B9%EC%9C%A4_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']= 500\n",
        "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
        "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
        "args['momentum']=0.9 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "args['weight_decay']=1e-5\n",
        "\n",
        "args['seed']=1 #random seed\n",
        "args['log_interval']=5000 // args['batch_size']\n",
        "args['cuda']=True\n"
      ],
      "metadata": {
        "id": "QrIE9UAm0d0b"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "FoWYQ5rfLSLH"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms # Fashion-MNIST dataset for PyTorch\n",
        "# Download and load the FashionMNIST training data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True,\n",
        "transform = transform)\n",
        "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False,\n",
        "transform = transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args['batch_size'], shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=args['batch_size'], shuffle=True)"
      ],
      "metadata": {
        "id": "FbEBR-PBNQbC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset # 28 * 28 * 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZcKmEcXa6BP",
        "outputId": "b45d81e9-bdd3-4432-f552-2a227e2b30f3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: MNIST_data/\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5,), std=(0.5,))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6yjaet1MoX-Z"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, groups=groups, bias=False)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
      ],
      "metadata": {
        "id": "-lSZGD5wndIa"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64,  norm_layer=nn.BatchNorm2d):\n",
        "      \n",
        "        super().__init__()\n",
        "            \n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)  \n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "            \n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "BKX_QBynryp8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 2\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, norm_layer=nn.BatchNorm2d):\n",
        "        super().__init__()\n",
        "\n",
        "        # ResNext\n",
        "      # width = int(planes * (base_width / 64.)) * groups\n",
        "        width = planes\n",
        "        \n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups) # conv2에서 downsample\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        # 1x1 convolution layer\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        # 3x3 convolution layer\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        # 1x1 convolution layer\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "CimQEbX0sfJN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, layers, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, norm_layer=nn.BatchNorm2d):\n",
        "    super().__init__()\n",
        "    self.norm_layer = norm_layer\n",
        "    self.groups = groups\n",
        "    self.base_width = width_per_group\n",
        "\n",
        "    self.inplane = 64\n",
        "\n",
        "    #stage 1\n",
        "    self.conv1 = nn.Conv2d(1,self.inplane,kernel_size=7,stride = 2, padding = 3, bias = False)\n",
        "    self.bn1 = norm_layer(self.inplane)\n",
        "    self.relu = nn.ReLU(inplace = True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    #stage 2\n",
        "    self.layer1 = self.make_layer(block,64,layers[0])\n",
        "    #stage 3\n",
        "    self.layer2 = self.make_layer(block,128,layers[1],stride=2)\n",
        "    #stage 4\n",
        "    self.layer3 = self.make_layer(block,256,layers[2],stride=2)\n",
        "    #stage 5\n",
        "    self.layer4 = self.make_layer(block,512,layers[3],stride=2)\n",
        "    self.averpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512 * block.expansion,10)\n",
        "  \n",
        "  def make_layer(self,block,palnes,blocks,stride = 1):\n",
        "    norm_layer = self.norm_layer\n",
        "\n",
        "    down_channel = None\n",
        "    \n",
        "    if stride != 1 or self.inplane != block.expansion * palnes:\n",
        "      down_channel = nn.Sequential(conv1x1(self.inplane, palnes * block.expansion,stride),norm_layer(palnes * block.expansion))\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    layers.append(block(self.inplane, palnes, stride, down_channel, self.groups,self.base_width, norm_layer))\n",
        "    self.inplane = palnes * block.expansion # inplanes 업데이트\n",
        "    for _ in range(1, blocks):\n",
        "        layers.append(block(self.inplane, palnes, groups=self.groups,base_width=self.base_width, norm_layer=norm_layer))\n",
        "       # self.inplane = palnes * block.expansion # inplanes 업데이트\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "\n",
        "    x = self.averpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "   # output = nn.log_softmax(x, dim=1)\n",
        "    return F.log_softmax(x)"
      ],
      "metadata": {
        "id": "yjZKnwgct0hB"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "G_UN2T5709Rs"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        #Variables in Pytorch are differenciable. \n",
        "        data, target = Variable(data), Variable(target)\n",
        "        #This will zero out the gradients for this batch. \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        train_pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        train_correct += train_pred.eq(target.data.view_as(train_pred)).long().cpu().sum()\n",
        "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "        loss = F.nll_loss(output, target)\n",
        "        #dloss/dx for every Variable \n",
        "        loss.backward()\n",
        "        #to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        #Print out the loss periodically. \n",
        "        if batch_idx % args['log_interval'] == 0:\n",
        "            train_correct = 0\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
        "                100. * batch_idx / len(trainloader), loss.data))\n",
        "    train_acc.insert(len(train_acc),(100. * train_correct / len(trainloader.dataset)))\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    correct_top5 = 0\n",
        "    total = 0\n",
        "    total_r=0\n",
        "    correct_top1=0\n",
        "    for data, target in testloader:\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "        _, predicted = torch.topk(output, k=5, dim=1)\n",
        "        total += target.size(0)\n",
        "        correct_top5 += sum([1 if label in predicted[i] else 0  for i,label in enumerate(target)])\n",
        "\n",
        "        __, predicted_r = torch.max(output, 1)\n",
        "        total_r += target.size(0)\n",
        "        correct_top1 += (predicted_r == target).sum().item()\n",
        "\n",
        "    test_loss /= len(testloader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        test_loss, correct, len(testloader.dataset),\n",
        "        100. * correct / len(testloader.dataset)))\n",
        "    test_acc.insert(len(test_acc),(100. * correct / len(testloader.dataset)))\n",
        "    top5_accuracy = correct_top5 / total\n",
        "    print(f\"Top-5 Accuracy: {top5_accuracy}\")\n",
        "    top1_accuracy = correct_top1 / total_r\n",
        "    print(f\"Top-1 Accuracy: {top1_accuracy}\\n\")\n",
        "  "
      ],
      "metadata": {
        "id": "URFhhVfUutlU"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9iyKkvXDkUc",
        "outputId": "3f4790cc-436a-4c42-a8a3-878944154ccb"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ptflops in /usr/local/lib/python3.10/dist-packages (0.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->ptflops) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->ptflops) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from ptflops import get_model_complexity_info\n",
        "import math\n",
        "import time"
      ],
      "metadata": {
        "id": "6m_HDnysAp5c"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "model = ResNet(Bottleneck,[3,4,6,3])\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'],weight_decay=args['weight_decay'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "\n",
        "  input_tensor = torch.randn(1, 1, 224, 224).cuda()\n",
        "\n",
        "  flops, params = get_model_complexity_info(model, (1, 224, 224), as_strings=True, print_per_layer_stat=True)\n",
        "\n",
        "  print('FLOPs:', flops)\n",
        "\n",
        "  print('Parameters:', params)\n",
        "\n",
        "\n",
        "print(test_acc)\n",
        "print(train_acc)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot([i for i in range(1,len(test_acc)+1)], test_acc, color =\"blue\")\n",
        "a = plt.twinx()\n",
        "a.plot([i for i in range(1,len(train_acc)+1)], train_acc, color = \"red\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j6MJRqJ20YDM",
        "outputId": "17480584-c2b8-48b5-e08b-404e5a1faebe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a8a4df10e8b6>:60: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.406816\n",
            "Train Epoch: 1 [4992/60000 (8%)]\tLoss: 1.405889\n",
            "Train Epoch: 1 [9984/60000 (17%)]\tLoss: 0.704245\n",
            "Train Epoch: 1 [14976/60000 (25%)]\tLoss: 1.337250\n",
            "Train Epoch: 1 [19968/60000 (33%)]\tLoss: 1.073333\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.599222\n",
            "Train Epoch: 1 [29952/60000 (50%)]\tLoss: 0.531843\n",
            "Train Epoch: 1 [34944/60000 (58%)]\tLoss: 0.600743\n",
            "Train Epoch: 1 [39936/60000 (67%)]\tLoss: 0.470299\n",
            "Train Epoch: 1 [44928/60000 (75%)]\tLoss: 0.519484\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.160815\n",
            "Train Epoch: 1 [54912/60000 (92%)]\tLoss: 1.337936\n",
            "Train Epoch: 1 [59904/60000 (100%)]\tLoss: 1.107745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-d3b87ec97dcd>:38: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data, target = Variable(data, volatile=True), Variable(target)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7313, Accuracy: 7027/10000 (70%)\n",
            "Top-5 Accuracy: 0.982\n",
            "Top-1 Accuracy: 0.7027\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.423078\n",
            "Train Epoch: 2 [4992/60000 (8%)]\tLoss: 0.906608\n",
            "Train Epoch: 2 [9984/60000 (17%)]\tLoss: 0.985991\n",
            "Train Epoch: 2 [14976/60000 (25%)]\tLoss: 2.189669\n",
            "Train Epoch: 2 [19968/60000 (33%)]\tLoss: 0.828606\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.235294\n",
            "Train Epoch: 2 [29952/60000 (50%)]\tLoss: 0.355261\n",
            "Train Epoch: 2 [34944/60000 (58%)]\tLoss: 0.315186\n",
            "Train Epoch: 2 [39936/60000 (67%)]\tLoss: 0.346497\n",
            "Train Epoch: 2 [44928/60000 (75%)]\tLoss: 0.553041\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.747050\n",
            "Train Epoch: 2 [54912/60000 (92%)]\tLoss: 0.581645\n",
            "Train Epoch: 2 [59904/60000 (100%)]\tLoss: 0.676605\n",
            "\n",
            "Test set: Average loss: 0.4949, Accuracy: 8301/10000 (83%)\n",
            "Top-5 Accuracy: 0.997\n",
            "Top-1 Accuracy: 0.8301\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.303821\n",
            "Train Epoch: 3 [4992/60000 (8%)]\tLoss: 0.680971\n",
            "Train Epoch: 3 [9984/60000 (17%)]\tLoss: 0.527340\n",
            "Train Epoch: 3 [14976/60000 (25%)]\tLoss: 1.281977\n",
            "Train Epoch: 3 [19968/60000 (33%)]\tLoss: 0.323620\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.530976\n",
            "Train Epoch: 3 [29952/60000 (50%)]\tLoss: 1.209751\n",
            "Train Epoch: 3 [34944/60000 (58%)]\tLoss: 0.544883\n",
            "Train Epoch: 3 [39936/60000 (67%)]\tLoss: 0.552725\n",
            "Train Epoch: 3 [44928/60000 (75%)]\tLoss: 1.506241\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.411214\n",
            "Train Epoch: 3 [54912/60000 (92%)]\tLoss: 0.619396\n",
            "Train Epoch: 3 [59904/60000 (100%)]\tLoss: 0.482986\n",
            "\n",
            "Test set: Average loss: 0.4583, Accuracy: 8262/10000 (83%)\n",
            "Top-5 Accuracy: 0.9969\n",
            "Top-1 Accuracy: 0.8262\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.386676\n",
            "Train Epoch: 4 [4992/60000 (8%)]\tLoss: 0.534998\n",
            "Train Epoch: 4 [9984/60000 (17%)]\tLoss: 0.474868\n",
            "Train Epoch: 4 [14976/60000 (25%)]\tLoss: 0.408153\n",
            "Train Epoch: 4 [19968/60000 (33%)]\tLoss: 0.483043\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.385149\n",
            "Train Epoch: 4 [29952/60000 (50%)]\tLoss: 0.271278\n",
            "Train Epoch: 4 [34944/60000 (58%)]\tLoss: 0.457162\n",
            "Train Epoch: 4 [39936/60000 (67%)]\tLoss: 0.314338\n",
            "Train Epoch: 4 [44928/60000 (75%)]\tLoss: 0.380070\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.202413\n",
            "Train Epoch: 4 [54912/60000 (92%)]\tLoss: 0.303291\n",
            "Train Epoch: 4 [59904/60000 (100%)]\tLoss: 0.443124\n",
            "\n",
            "Test set: Average loss: 0.4138, Accuracy: 8488/10000 (85%)\n",
            "Top-5 Accuracy: 0.9974\n",
            "Top-1 Accuracy: 0.8488\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.474597\n",
            "Train Epoch: 5 [4992/60000 (8%)]\tLoss: 0.395437\n",
            "Train Epoch: 5 [9984/60000 (17%)]\tLoss: 0.323281\n",
            "Train Epoch: 5 [14976/60000 (25%)]\tLoss: 0.597322\n",
            "Train Epoch: 5 [19968/60000 (33%)]\tLoss: 0.428332\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 1.091170\n",
            "Train Epoch: 5 [29952/60000 (50%)]\tLoss: 0.287248\n",
            "Train Epoch: 5 [34944/60000 (58%)]\tLoss: 0.402201\n",
            "Train Epoch: 5 [39936/60000 (67%)]\tLoss: 0.225948\n",
            "Train Epoch: 5 [44928/60000 (75%)]\tLoss: 0.401453\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.375098\n",
            "Train Epoch: 5 [54912/60000 (92%)]\tLoss: 0.291636\n",
            "Train Epoch: 5 [59904/60000 (100%)]\tLoss: 0.607253\n",
            "\n",
            "Test set: Average loss: 0.3812, Accuracy: 8580/10000 (86%)\n",
            "Top-5 Accuracy: 0.9977\n",
            "Top-1 Accuracy: 0.858\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.577271\n",
            "Train Epoch: 6 [4992/60000 (8%)]\tLoss: 0.258884\n",
            "Train Epoch: 6 [9984/60000 (17%)]\tLoss: 0.143466\n",
            "Train Epoch: 6 [14976/60000 (25%)]\tLoss: 0.403387\n",
            "Train Epoch: 6 [19968/60000 (33%)]\tLoss: 0.157006\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.365891\n",
            "Train Epoch: 6 [29952/60000 (50%)]\tLoss: 0.510057\n",
            "Train Epoch: 6 [34944/60000 (58%)]\tLoss: 0.252218\n",
            "Train Epoch: 6 [39936/60000 (67%)]\tLoss: 0.568828\n",
            "Train Epoch: 6 [44928/60000 (75%)]\tLoss: 0.374979\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.688075\n",
            "Train Epoch: 6 [54912/60000 (92%)]\tLoss: 0.268226\n",
            "Train Epoch: 6 [59904/60000 (100%)]\tLoss: 0.650163\n",
            "\n",
            "Test set: Average loss: 0.4022, Accuracy: 8532/10000 (85%)\n",
            "Top-5 Accuracy: 0.9973\n",
            "Top-1 Accuracy: 0.8532\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.063868\n",
            "Train Epoch: 7 [4992/60000 (8%)]\tLoss: 0.234996\n",
            "Train Epoch: 7 [9984/60000 (17%)]\tLoss: 0.304592\n",
            "Train Epoch: 7 [14976/60000 (25%)]\tLoss: 0.259081\n",
            "Train Epoch: 7 [19968/60000 (33%)]\tLoss: 0.695087\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.128300\n",
            "Train Epoch: 7 [29952/60000 (50%)]\tLoss: 0.236009\n",
            "Train Epoch: 7 [34944/60000 (58%)]\tLoss: 0.386136\n",
            "Train Epoch: 7 [39936/60000 (67%)]\tLoss: 0.135747\n",
            "Train Epoch: 7 [44928/60000 (75%)]\tLoss: 0.305563\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.382062\n",
            "Train Epoch: 7 [54912/60000 (92%)]\tLoss: 0.430686\n",
            "Train Epoch: 7 [59904/60000 (100%)]\tLoss: 0.719333\n",
            "\n",
            "Test set: Average loss: 0.4795, Accuracy: 8610/10000 (86%)\n",
            "Top-5 Accuracy: 0.9976\n",
            "Top-1 Accuracy: 0.861\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.382403\n",
            "Train Epoch: 8 [4992/60000 (8%)]\tLoss: 0.289764\n",
            "Train Epoch: 8 [9984/60000 (17%)]\tLoss: 0.437789\n",
            "Train Epoch: 8 [14976/60000 (25%)]\tLoss: 0.204251\n",
            "Train Epoch: 8 [19968/60000 (33%)]\tLoss: 0.228459\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.319858\n",
            "Train Epoch: 8 [29952/60000 (50%)]\tLoss: 0.375243\n",
            "Train Epoch: 8 [34944/60000 (58%)]\tLoss: 0.725721\n",
            "Train Epoch: 8 [39936/60000 (67%)]\tLoss: 0.768016\n",
            "Train Epoch: 8 [44928/60000 (75%)]\tLoss: 0.118209\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.680334\n",
            "Train Epoch: 8 [54912/60000 (92%)]\tLoss: 0.196605\n",
            "Train Epoch: 8 [59904/60000 (100%)]\tLoss: 0.375985\n",
            "\n",
            "Test set: Average loss: 0.3335, Accuracy: 8780/10000 (88%)\n",
            "Top-5 Accuracy: 0.9975\n",
            "Top-1 Accuracy: 0.878\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.231800\n",
            "Train Epoch: 9 [4992/60000 (8%)]\tLoss: 0.141287\n",
            "Train Epoch: 9 [9984/60000 (17%)]\tLoss: 0.197776\n",
            "Train Epoch: 9 [14976/60000 (25%)]\tLoss: 0.243504\n",
            "Train Epoch: 9 [19968/60000 (33%)]\tLoss: 0.226776\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.631256\n",
            "Train Epoch: 9 [29952/60000 (50%)]\tLoss: 0.185188\n",
            "Train Epoch: 9 [34944/60000 (58%)]\tLoss: 0.321329\n",
            "Train Epoch: 9 [39936/60000 (67%)]\tLoss: 0.268268\n",
            "Train Epoch: 9 [44928/60000 (75%)]\tLoss: 0.267521\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.297241\n",
            "Train Epoch: 9 [54912/60000 (92%)]\tLoss: 0.056529\n",
            "Train Epoch: 9 [59904/60000 (100%)]\tLoss: 0.328540\n",
            "\n",
            "Test set: Average loss: 0.3349, Accuracy: 8667/10000 (87%)\n",
            "Top-5 Accuracy: 0.9984\n",
            "Top-1 Accuracy: 0.8667\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.203400\n",
            "Train Epoch: 10 [4992/60000 (8%)]\tLoss: 0.179307\n",
            "Train Epoch: 10 [9984/60000 (17%)]\tLoss: 0.210284\n",
            "Train Epoch: 10 [14976/60000 (25%)]\tLoss: 0.128956\n",
            "Train Epoch: 10 [19968/60000 (33%)]\tLoss: 0.408737\n",
            "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.276657\n",
            "Train Epoch: 10 [29952/60000 (50%)]\tLoss: 0.637649\n",
            "Train Epoch: 10 [34944/60000 (58%)]\tLoss: 0.374897\n",
            "Train Epoch: 10 [39936/60000 (67%)]\tLoss: 0.275084\n",
            "Train Epoch: 10 [44928/60000 (75%)]\tLoss: 0.359059\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.300333\n",
            "Train Epoch: 10 [54912/60000 (92%)]\tLoss: 0.164166\n",
            "Train Epoch: 10 [59904/60000 (100%)]\tLoss: 0.435908\n",
            "\n",
            "Test set: Average loss: 0.3176, Accuracy: 8845/10000 (88%)\n",
            "Top-5 Accuracy: 0.9987\n",
            "Top-1 Accuracy: 0.8845\n",
            "\n",
            "683.69089 sec\n",
            "ResNet(\n",
            "  23.52 M, 100.000% Params, 4.04 GMac, 100.000% MACs, \n",
            "  (conv1): Conv2d(3.14 k, 0.013% Params, 39.34 MMac, 0.973% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.040% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.020% MACs, inplace=True)\n",
            "  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.020% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    215.81 k, 0.917% Params, 680.39 MMac, 16.836% MACs, \n",
            "    (0): Bottleneck(\n",
            "      75.01 k, 0.319% Params, 236.43 MMac, 5.850% MACs, \n",
            "      (conv1): Conv2d(4.1 k, 0.017% Params, 12.85 MMac, 0.318% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(36.86 k, 0.157% Params, 115.61 MMac, 2.861% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.040% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.030% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        16.9 k, 0.072% Params, 52.99 MMac, 1.311% MACs, \n",
            "        (0): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.040% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      70.4 k, 0.299% Params, 221.98 MMac, 5.493% MACs, \n",
            "      (conv1): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(36.86 k, 0.157% Params, 115.61 MMac, 2.861% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.040% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.030% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      70.4 k, 0.299% Params, 221.98 MMac, 5.493% MACs, \n",
            "      (conv1): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(36.86 k, 0.157% Params, 115.61 MMac, 2.861% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(16.38 k, 0.070% Params, 51.38 MMac, 1.271% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.040% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.030% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    1.22 M, 5.185% Params, 1.04 GMac, 25.649% MACs, \n",
            "    (0): Bottleneck(\n",
            "      379.39 k, 1.613% Params, 376.02 MMac, 9.305% MACs, \n",
            "      (conv1): Conv2d(32.77 k, 0.139% Params, 102.76 MMac, 2.543% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.020% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(147.46 k, 0.627% Params, 115.61 MMac, 2.861% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        132.1 k, 0.562% Params, 103.56 MMac, 2.563% MACs, \n",
            "        (0): Conv2d(131.07 k, 0.557% Params, 102.76 MMac, 2.543% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      280.06 k, 1.191% Params, 220.17 MMac, 5.448% MACs, \n",
            "      (conv1): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(147.46 k, 0.627% Params, 115.61 MMac, 2.861% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      280.06 k, 1.191% Params, 220.17 MMac, 5.448% MACs, \n",
            "      (conv1): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(147.46 k, 0.627% Params, 115.61 MMac, 2.861% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      280.06 k, 1.191% Params, 220.17 MMac, 5.448% MACs, \n",
            "      (conv1): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(147.46 k, 0.627% Params, 115.61 MMac, 2.861% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(65.54 k, 0.279% Params, 51.38 MMac, 1.271% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.020% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    7.1 M, 30.177% Params, 1.47 GMac, 36.390% MACs, \n",
            "    (0): Bottleneck(\n",
            "      1.51 M, 6.430% Params, 374.26 MMac, 9.261% MACs, \n",
            "      (conv1): Conv2d(131.07 k, 0.557% Params, 102.76 MMac, 2.543% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        526.34 k, 2.238% Params, 103.16 MMac, 2.553% MACs, \n",
            "        (0): Conv2d(524.29 k, 2.229% Params, 102.76 MMac, 2.543% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      1.12 M, 4.749% Params, 219.27 MMac, 5.426% MACs, \n",
            "      (conv1): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(589.82 k, 2.508% Params, 115.61 MMac, 2.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(262.14 k, 1.114% Params, 51.38 MMac, 1.271% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    14.96 M, 63.619% Params, 811.02 MMac, 20.069% MACs, \n",
            "    (0): Bottleneck(\n",
            "      6.04 M, 25.676% Params, 373.38 MMac, 9.239% MACs, \n",
            "      (conv1): Conv2d(524.29 k, 2.229% Params, 102.76 MMac, 2.543% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(2.36 M, 10.030% Params, 115.61 MMac, 2.861% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(4.1 k, 0.017% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.006% MACs, inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        2.1 M, 8.933% Params, 102.96 MMac, 2.548% MACs, \n",
            "        (0): Conv2d(2.1 M, 8.916% Params, 102.76 MMac, 2.543% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(4.1 k, 0.017% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      4.46 M, 18.972% Params, 218.82 MMac, 5.415% MACs, \n",
            "      (conv1): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(2.36 M, 10.030% Params, 115.61 MMac, 2.861% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(4.1 k, 0.017% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      4.46 M, 18.972% Params, 218.82 MMac, 5.415% MACs, \n",
            "      (conv1): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(2.36 M, 10.030% Params, 115.61 MMac, 2.861% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1.05 M, 4.458% Params, 51.38 MMac, 1.271% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(4.1 k, 0.017% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (averpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))\n",
            "  (fc): Linear(20.49 k, 0.087% Params, 20.49 KMac, 0.001% MACs, in_features=2048, out_features=10, bias=True)\n",
            ")\n",
            "FLOPs: 4.04 GMac\n",
            "Parameters: 23.52 M\n",
            "[tensor(70.2700), tensor(83.0100), tensor(82.6200), tensor(84.8800), tensor(85.8000), tensor(85.3200), tensor(86.1000), tensor(87.8000), tensor(86.6700), tensor(88.4500)]\n",
            "[tensor(0.0783), tensor(0.0783), tensor(0.0800), tensor(0.0950), tensor(0.0850), tensor(0.0900), tensor(0.0867), tensor(0.0967), tensor(0.0917), tensor(0.1000)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNeXt\n",
        "torch.cuda.empty_cache()\n",
        "start = time.time()\n",
        "model = ResNet(Bottleneck,[3,4,6,3],groups=16)\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'],weight_decay=args['weight_decay'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "end = time.time()\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "\n",
        "  input_tensor = torch.randn(1, 1, 224, 224).cuda()\n",
        "\n",
        "  flops, params = get_model_complexity_info(model, (1, 224, 224), as_strings=True, print_per_layer_stat=True)\n",
        "\n",
        "  print('FLOPs:', flops)\n",
        "\n",
        "  print('Parameters:', params)\n",
        "\n",
        "\n",
        "print(test_acc)\n",
        "print(train_acc)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot([i for i in range(1,len(test_acc)+1)], test_acc, color =\"blue\")\n",
        "a = plt.twinx()\n",
        "a.plot([i for i in range(1,len(train_acc)+1)], train_acc, color = \"red\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IL_sKr34slks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}